{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define directory with context files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './context/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all files present in given directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.pdf'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        loader = PyPDFLoader(filepath)\n",
    "        documents = loader.load()\n",
    "        all_documents.extend(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(all_documents)\n",
    "\n",
    "print(f'Total number of chunks: {len(texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "print('embedding model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Vector DB or Create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('Loading from saved db')\n",
    "    docsearch = Chroma(embedding_function=embeddings, persist_directory=\"chroma_db\")\n",
    "    print('document loaded')\n",
    "except:\n",
    "    print('Creating new db')\n",
    "    docsearch = Chroma.from_documents(texts, embeddings, persist_directory=\"chroma_db\")\n",
    "    docsearch.persist()\n",
    "    print('document ingested')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a LLM/SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"phi3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a legal expert. Your role is to provide clear and accurate legal advice only based on the information from the provided documents and previous conversations with the user. If you don't know the answer, just say that you don't know, definately do not try to make up an answer.\n",
    "\n",
    "Previous conversations:\n",
    "{history}\n",
    "\n",
    "Document context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"history\", \"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function with Retrival Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnAsk():\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=docsearch.as_retriever(),\n",
    "                                    verbose=False,\n",
    "                                    chain_type_kwargs={\n",
    "                                        \"verbose\": False,\n",
    "                                        \"prompt\": PROMPT,\n",
    "                                        \"memory\": ConversationBufferMemory(\n",
    "                                            memory_key=\"history\",\n",
    "                                            input_key=\"question\"),\n",
    "                                    }, \n",
    "                                    return_source_documents=False)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"Question: \")\n",
    "\n",
    "        print(\"User: \", query, \"\\n\")\n",
    "        if query.lower() in [\"quit\",\"exit\",\"bye\"]:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        result = qa.invoke(query)\n",
    "\n",
    "        print(\"Bot: \", result[\"result\"], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnAsk()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
